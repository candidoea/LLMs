## ğŸ§  Arquitetura Transformer Autoregressiva â€” DescriÃ§Ã£o TÃ©cnica

Este projeto implementa um **Transformer decoder-only autoregressivo** para modelagem de linguagem.
Dada uma sequÃªncia de tokens, o modelo aprende a estimar a distribuiÃ§Ã£o condicional do prÃ³ximo token:

O treinamento maximiza a log-verossimilhanÃ§a dos dados (equivalente Ã  minimizaÃ§Ã£o da cross-entropy).

---

## ğŸ“¥ RepresentaÃ§Ã£o de Entrada

Cada token discreto () Ã© mapeado para um vetor contÃ­nuo por uma matriz de embeddings:

Para incorporar ordem sequencial, adicionamos embeddings posicionais:

onde () representa a posiÃ§Ã£o do token.

---

## ğŸ” Bloco Transformer

O modelo Ã© composto por () blocos idÃªnticos. Cada bloco contÃ©m:

1. **Masked Multi-Head Self-Attention**
2. **Feed-Forward Network**
3. **ConexÃµes residuais**
4. **Layer Normalization**

Para a camada ():

---

## ğŸ¯ Self-Attention com MÃ¡scara Causal

Para uma sequÃªncia de comprimento (), definimos:

onde:

* 
* 

A atenÃ§Ã£o escalada:

A **mÃ¡scara causal** () impede acesso ao futuro:

Isso garante fatoraÃ§Ã£o autoregressiva da distribuiÃ§Ã£o conjunta.

---

## ğŸ§© Multi-Head Attention

A atenÃ§Ã£o Ã© aplicada em paralelo em () cabeÃ§as:

---

## ğŸ§® Feed-Forward Position-Wise

Aplicado independentemente em cada posiÃ§Ã£o:

Normalmente: 

---

## ğŸ”„ Residual + Normalization

Cada subcamada usa residual connection:

---

## ğŸ“¤ Camada de SaÃ­da

A representaÃ§Ã£o final  Ã© projetada no vocabulÃ¡rio:

Probabilidades:

---

## ğŸ“ FunÃ§Ã£o de Perda

Treinamento por mÃ¡xima verossimilhanÃ§a:

Equivalente Ã  **cross-entropy token-wise**.

---

## âœï¸ GeraÃ§Ã£o Autoregressiva

Durante inferÃªncia:

1. Entrada inicial ()
2. Computar 
3. Amostrar ou escolher `argmax`
4. Concatenar e repetir

---

## ğŸ“ Complexidade

Self-attention densa:

onde () Ã© o comprimento da sequÃªncia.

---

## âœ… Propriedades do Modelo

* Modelagem autoregressiva explÃ­cita
* DependÃªncias globais via atenÃ§Ã£o
* ParalelizaÃ§Ã£o total no treinamento
* FatoraÃ§Ã£o causal garantida pela mÃ¡scara triangular

---
