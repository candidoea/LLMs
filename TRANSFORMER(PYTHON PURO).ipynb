{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff13f6df-1f4a-412b-b56c-c664cb033754",
   "metadata": {},
   "source": [
    "üèóÔ∏è IMPLEMENTAR TRANSFORMER DO ZERO (PYTHON PURO)\n",
    "\n",
    "Sem PyTorch, TensorFlow etc.\n",
    "S√≥ matem√°tica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e963c45-21aa-485b-a542-171f525fce18",
   "metadata": {},
   "source": [
    "üìå Estrutura que construiremos:\n",
    "\n",
    "1 - embeddings\n",
    "2 - positional encoding\n",
    "3 - self-attention\n",
    "4 - feedforward\n",
    "5 - encoder layer\n",
    "6 - stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd58421f-899b-4f2b-9073-e9b1ba66091a",
   "metadata": {},
   "source": [
    "üìå Opera√ß√µes b√°sicas\n",
    "Multiplica√ß√£o matricial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5d7b32a-173d-4daf-895a-2e8fc1be932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(A, B):\n",
    "    result = [[0]*len(B[0]) for _ in range(len(A))]\n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(B[0])):\n",
    "            for k in range(len(B)):\n",
    "                result[i][j] += A[i][k]*B[k][j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc79f17-6e2c-41e6-b518-dd1912626a31",
   "metadata": {},
   "source": [
    "Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f15216d-ad10-4724-a4aa-d025752e4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def softmax_row(row):\n",
    "    exps = [math.exp(x) for x in row]\n",
    "    s = sum(exps)\n",
    "    return [e/s for e in exps]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e71cc3-928b-44f1-9e73-5781b9c03d7c",
   "metadata": {},
   "source": [
    "üìå Self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29d7df45-eb9e-43bd-ad1b-5c31440a7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(M):\n",
    "    return list(map(list, zip(*M)))\n",
    "\n",
    "def scale_matrix(M, scalar):\n",
    "    return [[x/scalar for x in row] for row in M]\n",
    "\n",
    "def apply_softmax(M):\n",
    "    return [softmax_row(row) for row in M]\n",
    "\n",
    "def self_attention(X, Wq, Wk, Wv):\n",
    "    Q = matmul(X, Wq)\n",
    "    K = matmul(X, Wk)\n",
    "    V = matmul(X, Wv)\n",
    "\n",
    "    KT = transpose(K)\n",
    "    scores = matmul(Q, KT)\n",
    "\n",
    "    dk = len(K[0])\n",
    "    scores = scale_matrix(scores, math.sqrt(dk))\n",
    "\n",
    "    A = apply_softmax(scores)\n",
    "\n",
    "    Z = matmul(A, V)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7894638c-b0f9-42b2-94b4-fe0e5332c7e8",
   "metadata": {},
   "source": [
    "üìå Feedforward network\n",
    "\n",
    "Duas camadas lineares + ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18b82a94-9f5e-4c57-94c2-4f5be0594ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def feedforward(X, W1, W2):\n",
    "    H = matmul(X, W1)\n",
    "    H = [[relu(v) for v in row] for row in H]\n",
    "    return matmul(H, W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251bfa34-3e9d-421b-b1f5-b1a957577e3e",
   "metadata": {},
   "source": [
    "üìå Encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62f7ea72-89fc-40e7-b9f8-7552a9b78f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(X, Wq, Wk, Wv, W1, W2):\n",
    "    att = self_attention(X, Wq, Wk, Wv)\n",
    "    ff = feedforward(att, W1, W2)\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce32a0-aaf2-415e-a925-564d6dbdf7b0",
   "metadata": {},
   "source": [
    "üìå Transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8e90d20-38b8-46c7-844e-f540ed5b5651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(X, layers):\n",
    "    for layer in layers:\n",
    "        X = encoder_layer(X, *layer)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f544012-83a6-4ca0-bcad-2a466e233b6a",
   "metadata": {},
   "source": [
    "üß™ 2. Testar o c√≥digo\n",
    "\n",
    "O modelo precisa de tr√™s coisas:\n",
    "\n",
    "dados de entrada (matriz X)\n",
    "\n",
    "pesos (Wq, Wk, Wv, W1, W2)\n",
    "\n",
    "execu√ß√£o do encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40c783b-c8e8-47b0-9b82-8f5c7362add6",
   "metadata": {},
   "source": [
    "‚úÖ Passo 1 ‚Äî criar uma frase tokenizada\n",
    "\n",
    "Vamos usar 4 tokens com embedding dimens√£o 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1897d65-a9ed-4980-a662-986ef89f6100",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\n",
    "    [1, 0, 1, 0],   # token 1\n",
    "    [0, 1, 0, 1],   # token 2\n",
    "    [1, 1, 0, 0],   # token 3\n",
    "    [0, 0, 1, 1]    # token 4\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbcdea8-9945-4aa9-bd43-5a65fe7e2f9f",
   "metadata": {},
   "source": [
    "‚úÖ Passo 2 ‚Äî criar pesos aleat√≥rios\n",
    "\n",
    "Sem numpy ‚Äî vamos gerar manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60fe7c95-46d6-4437-96dd-7788eeed4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_matrix(rows, cols):\n",
    "    return [[random.uniform(-1,1) for _ in range(cols)] for _ in range(rows)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142a6de-b9f5-45cf-b4c2-4771d59fa3d5",
   "metadata": {},
   "source": [
    "Agora definimos dimens√µes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47adeedb-b607-46c0-bd02-5ee7da150d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 4\n",
    "d_k = 4\n",
    "d_ff = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb6f30-b73c-48f3-aa87-bec7fbaa162a",
   "metadata": {},
   "source": [
    "Pesos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7c01577-4442-4efe-b629-0e8d6d57f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wq = random_matrix(d_model, d_k)\n",
    "Wk = random_matrix(d_model, d_k)\n",
    "Wv = random_matrix(d_model, d_k)\n",
    "\n",
    "W1 = random_matrix(d_k, d_ff)\n",
    "W2 = random_matrix(d_ff, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b68b2d-32d7-49be-9736-4a80f8e60010",
   "metadata": {},
   "source": [
    "‚úÖ Passo 3 ‚Äî montar camada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fadd693-9092-4896-a4af-24ed27d8b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = (Wq, Wk, Wv, W1, W2)\n",
    "layers = [layer]   # uma camada s√≥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96715aad-626b-4d7a-abfb-234d0619e091",
   "metadata": {},
   "source": [
    "‚úÖ Passo 4 ‚Äî rodar Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12e4becf-f4aa-4f03-98e5-a63c0e885b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = transformer_encoder(X, layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d599f82-56ba-4028-b1c9-1aba9f24386f",
   "metadata": {},
   "source": [
    "‚úÖ Passo 5 ‚Äî visualizar resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9db7b205-af46-4e0a-b8c0-56ebb1bf614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.294, -1.333, 0.79, 0.47]\n",
      "[0.363, -1.679, 1.098, 0.675]\n",
      "[0.338, -1.524, 0.955, 0.584]\n",
      "[0.32, -1.493, 0.937, 0.564]\n"
     ]
    }
   ],
   "source": [
    "for row in output:\n",
    "    print([round(v, 3) for v in row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c44a75f-babb-42f7-b726-18dd1b2540d6",
   "metadata": {},
   "source": [
    "Isso significa:\n",
    "\n",
    "üëâ o modelo transformou representa√ß√µes considerando rela√ß√µes entre tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ed506d-c418-4b18-ab20-a8bd33896de6",
   "metadata": {},
   "source": [
    "üß† 4. Validar matematicamente se est√° correto\n",
    "\n",
    "Propriedades esperadas:\n",
    "\n",
    "‚úî sa√≠da dimens√£o igual entrada\n",
    "‚úî valores diferentes da entrada\n",
    "‚úî mudan√ßa em um token afeta todos\n",
    "‚úî pesos softmax somam 1 por linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ffd2aaf-fd1a-476d-a6b0-8456fd4fcf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = matmul(X, Wq)\n",
    "K = matmul(X, Wk)\n",
    "\n",
    "KT = transpose(K)\n",
    "scores = matmul(Q, KT)\n",
    "\n",
    "dk = len(K[0])\n",
    "scores = scale_matrix(scores, math.sqrt(dk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30048679-87ad-4367-8c81-06af95f8ad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "A = apply_softmax(scores)\n",
    "print(sum(A[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4614323e-bf5e-46df-85b7-6cd910f0a7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0000000000000002\n",
      "1 1.0\n",
      "2 1.0\n",
      "3 1.0\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(A):\n",
    "    print(i, sum(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a65dc-7af1-4de1-b2d8-52052f852f7b",
   "metadata": {},
   "source": [
    "Todas as linhas devem somar ~1.\n",
    "\n",
    "Isso prova que softmax est√° correto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "86d30cb5-fba9-42e4-b50b-f8b57e121aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:\n",
      "[0.7125825936326802, 0.039155851132483425, 0.09815608097241141, 0.6535823637927521]\n",
      "[-0.5846683550693962, 0.06150154301447563, 0.20374083058146494, -0.7269076426363856]\n",
      "[-0.0902925539497873, -0.1336315214662327, 0.02097908491247466, -0.24490316032849466]\n",
      "[0.2182067925130713, 0.23428891561319176, 0.2809178266414017, 0.1715778814848613]\n",
      "\n",
      "attention weights:\n",
      "[0.33404421587589184, 0.17034854870418567, 0.180701564293849, 0.31490567112607365]\n",
      "[0.1673492890688991, 0.31933894990052175, 0.3681506999699061, 0.14516106106067314]\n",
      "[0.2543213039172209, 0.2435347094108621, 0.28425453379354937, 0.2178894528783677]\n",
      "[0.24780858050178625, 0.2518260870274284, 0.2638465355652551, 0.23651879690553024]\n"
     ]
    }
   ],
   "source": [
    "print(\"scores:\")\n",
    "for r in scores:\n",
    "    print(r)\n",
    "\n",
    "print(\"\\nattention weights:\")\n",
    "for r in A:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fe6a3-919e-4bfc-a01e-982772593834",
   "metadata": {},
   "source": [
    "Observe:\n",
    "\n",
    "‚úî scores podem ser negativos ou grandes\n",
    "‚úî attention vira probabilidades\n",
    "‚úî cada linha √© distribui√ß√£o sobre tokens\n",
    "\n",
    "Isso √© fundamental para entender LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee894d7b-948a-471b-9999-7981d1a5afbc",
   "metadata": {},
   "source": [
    "‚öôÔ∏è Implementa√ß√£o no seu c√≥digo Python puro\n",
    "\n",
    "Vamos criar fun√ß√£o m√°scara."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7283141-df0e-4481-910a-a847f4522d7e",
   "metadata": {},
   "source": [
    "üìå Criar m√°scara triangular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6b18322f-6aa9-4953-a27a-762de60509f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def causal_mask(n):\n",
    "    M = []\n",
    "    for i in range(n):\n",
    "        row = []\n",
    "        for j in range(n):\n",
    "            if j > i:\n",
    "                row.append(-1e9)   # aproxima -‚àû\n",
    "            else:\n",
    "                row.append(0)\n",
    "        M.append(row)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eee9f74-d10d-4e23-b7f4-9c978afda894",
   "metadata": {},
   "source": [
    "üìå Somar m√°scara aos scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1d168f75-20c4-4035-8822-de98312f5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_matrices(A, B):\n",
    "    return [\n",
    "        [A[i][j] + B[i][j] for j in range(len(A[0]))]\n",
    "        for i in range(len(A))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74f35b-bd2f-49b6-84bb-60866f61cc62",
   "metadata": {},
   "source": [
    "üìå Self-attention com m√°scara causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0f8d9662-d05f-43e8-98c5-4fbc63adac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention_causal(X, Wq, Wk, Wv):\n",
    "    Q = matmul(X, Wq)\n",
    "    K = matmul(X, Wk)\n",
    "    V = matmul(X, Wv)\n",
    "\n",
    "    KT = transpose(K)\n",
    "    scores = matmul(Q, KT)\n",
    "\n",
    "    dk = len(K[0])\n",
    "    scores = scale_matrix(scores, math.sqrt(dk))\n",
    "\n",
    "    M = causal_mask(len(scores))\n",
    "    scores = add_matrices(scores, M)\n",
    "\n",
    "    A = apply_softmax(scores)\n",
    "    Z = matmul(A, V)\n",
    "    return Z, A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b985840-b6be-446f-b4e1-5646e6c01cc7",
   "metadata": {},
   "source": [
    "üî¨ Como testar se est√° funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "575fad35-3d58-4005-a74f-b08833181f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 0.0, 0.0]\n",
      "[0.34385316033785196, 0.656146839662148, 0.0, 0.0]\n",
      "[0.32517309075192585, 0.31138144129002276, 0.36344546795805155, 0.0]\n",
      "[0.24780858050178625, 0.2518260870274284, 0.2638465355652551, 0.23651879690553024]\n"
     ]
    }
   ],
   "source": [
    "Z, A = self_attention_causal(X, Wq, Wk, Wv)\n",
    "\n",
    "for row in A:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {
    "306046da-90ce-469e-9a6a-463b3506ecee.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "56948004-5564-41c2-afa8-a25127ec686f",
   "metadata": {},
   "source": [
    "üß† Interpreta√ß√£o profunda\n",
    "\n",
    "M√°scara causal transforma self-attention em:\n",
    "\n",
    "modelo autoregressivo fatorizado\n",
    "\n",
    "Ou seja, o modelo aprende:\n",
    "\n",
    "![image.png](attachment:306046da-90ce-469e-9a6a-463b3506ecee.png)\n",
    "\n",
    "Isso √© modelagem probabil√≠stica sequencial.\n",
    "\n",
    "‚ö° Por que isso √© ESSENCIAL para modelos geradores\n",
    "\n",
    "Sem m√°scara:\n",
    "\n",
    "‚úî modelo v√™ resposta correta durante treino\n",
    "‚úî perda artificialmente baixa\n",
    "‚úî n√£o aprende gera√ß√£o real\n",
    "\n",
    "Com m√°scara:\n",
    "\n",
    "‚úî aprende depend√™ncia temporal\n",
    "‚úî consegue gerar token por token\n",
    "‚úî comportamento de linguagem natural\n",
    "\n",
    "üß† Insight\n",
    "\n",
    "M√°scara causal n√£o √© apenas ‚Äúbloqueio‚Äù.\n",
    "\n",
    "Ela define a estrutura do grafo computacional do modelo.\n",
    "\n",
    "Sem m√°scara ‚Üí grafo totalmente conectado\n",
    "Com m√°scara ‚Üí grafo direcionado no tempo\n",
    "\n",
    "Isso muda completamente a distribui√ß√£o modelada.\n",
    "\n",
    "üéØ Resumo em uma frase\n",
    "\n",
    "M√°scara causal impede que um token veja o futuro durante self-attention, permitindo modelagem probabil√≠stica autoregressiva correta para gera√ß√£o de texto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
